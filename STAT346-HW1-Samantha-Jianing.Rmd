---
title: "HW1"
author: "Jianing Ren"
date: "14/09/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

TEST THAT THIS IS WORKING. HI! - SAM

## 1 Bodyfat Revisited

```{r}
##setwd("/Users/rjn/OneDrive/大学/fall_2020/Stat 346/hw1")
bodyfat=read.delim("https://dasl.datadescription.com/download/data/3079")
```

### a Creating a Correlation Matrix

```{r}
cor_mat=cor(bodyfat)
cor_mat=cor_mat[2:8,2:8]
cor_mat
```

### b

```{r}
lm_waist=lm(Pct.BF~Waist,data=bodyfat)
plot(Pct.BF~Waist,data=bodyfat)+abline(lm_waist,col="red")
summary(lm_waist)
```

From the correlation matrix calculated before, the best regressors other than density which produces the highest absolute correlation coefficient are waist and abdomen, which are the same. 

After building a simple linear model between Pct.BF against Waist size, we see that the positive association is quite strong and the variation around the line is small. In fact, the $R^2$ value of the model is 0.68,suggesting the model rather accurately captures the total variance of percent bodyfat. 

### c describe the equation

Every one inch increase in waist size is associated with, on average, 1.70% increase in body fat. 

### d model assumptions

```{r}
par(mfrow=c(2,2))
plot(Pct.BF~Waist,data=bodyfat)+abline(lm_waist,col="red")
hist(lm_waist$residuals,main="Histogram of residuals")
plot(lm_waist$fitted.values,lm_waist$residuals,xlab="Predicted % bodyfat",ylab="Residuals",mai="Residual Plot")
qqnorm(lm_waist$residuals)
qqline(lm_waist$residuals)
```

The scatterplot between Pct.BF and Waist displays a linear relationship, and the residual scatterplot displays no special pattern. The histogram and the Normal QQ plot shows that the residuals are roughtly normally distributed with center around 0. Based on the information we have, we can assume the sample is random and representative of the population. 

### e predict % bf of 38-inch waist

```{r}
predict(lm_waist, newdata=data.frame(Waist=38))
```

We predict that, on average, a person with 38 inch of waist will have 21.86% bodyfat. 

### f Predict the % body fat of a man who has a 72 inch waist.

```{r}
predict(lm_waist, newdata=data.frame(Waist=72))

```

Based on our model, we would expect on average 79.66% bodyfat from a person with 72 inch of waist. We are not confident about this because our model is based on observations from about 25-50 inches of waist (as seen from the scatterplot before), and the waist size for which we are predicting here is way out of the scope of the model. This would be an example of extrapolation. 

## 2
### a

```{r}
suppressMessages(library("mosaic"))
set.seed(1000)
ss=sample(bodyfat,250,replace=T)
row.names(ss)
```

29.1 means that this is the second time that row 29 in the bodyfat data was picked for our bootstrap sample. The first time the row was picked from the bodyfat data, the row number in the bootstrap data was 29. The second time it was picked from the bodyfat data, the row number in the boostrap data was 29.1.

### b
```{r}
lm.b=lm(Pct.BF~Waist,data=ss)
coef(lm.b)
coef(lm_waist)
```

As shown side by side with my model in 1b, they aren't that different from each other. 

### c
```{r}
bootmat=matrix(nrow=1000,ncol=4)
set.seed(1000)
for (i in 1:1000)
{
    ss=sample(bodyfat,250,replace=T)
    lm.boot=lm(Pct.BF~Waist,data=ss)
    bootmat[i,]=c(coef(lm.boot),predict(lm.boot, newdata=data.frame(Waist=38)),predict(lm.boot, newdata=data.frame(Waist=72)))
}
```

```{r}
quantile(bootmat[,1],0.025)
quantile(bootmat[,1],0.975)
quantile(bootmat[,2],0.025)
quantile(bootmat[,2],0.975)

confint(lm_waist)
```

The bootstrap confidence interval for intercept is between -48.11 and -37.62, and that for the slope is between 1.56 and 1.85. Compared to the output from confint(), we can see that they are pretty similar. 

### d
```{r}
hist(bootmat[,3])
hist(bootmat[,4])
```

From the histograms of predicted values of 38 and 72 inches of waist, we see that the range for predicted bodyfat of 72 waist is much larger compared to that of 38 waist. This matches our intuition in f. Since we cannot be as confident in our body fat predictions for someone with a 72 inch waist than we are for someone with a 38 inch waist due to our data being concentrated around people with 25-50 inch waists, there has to be a wider range in possible percent body fat for someone with a 72 inch waist.

## 3

### a
```{r}
int=seq(-60,-30,len=100)
slope=seq(1.4,2,len=100)

get_sse=function(i,j)
{
    preds=int[i]+slope[j]*bodyfat$Waist
    sum((bodyfat$Pct.BF-preds)^2)
}

sse=matrix(nrow=100,ncol=100)
rownames(sse)=int
colnames(sse)=slope

for (i in 1:100)
{
    for (j in 1:100)
       sse[i,j]=get_sse(i,j) 
}

contour(int,slope,sse,nlevel=250)
```

When we clicked on points on the contour map using the locator, the closest we got to the actual least squares solution was an intercept of -42.919 and a slope of 1.710. This is pretty close to the intercept of -42.73 and a slope of 1.70 found with the least squares solution.

## 4

### a

```{r}
bigmac <- read.delim("bigmac.txt")
```

```{r}
plot(bigmac$BigMac~bigmac$EngSal, ylab="Price of a BigMac", xlab="Average Engineer's Salary")
## with(bigmac, scatter.smooth(BigMac~EngSal, pch=19, bty="n", cex=.8))
```

There doesn't appear to be a linear relationship; there appears to be a decreasing slope. This means that in countries where engineers are paid less on average, bigmacs cost more and in countries where engineers are paid more on average, bigmacs cost less.

### b
```{r}
lm.mac <- lm(BigMac~EngSal, data=bigmac)
par(mfrow=c(2,2))
plot(bigmac$EngSal, bigmac$BigMac, xlab="Average Engineer's Salary", ylab="Price of BigMac")
abline(lm.mac, col="red")
hist(lm.mac$residuals, main="Histogram of Residuals", xlab="Residuals")
plot(lm.mac$fitted.values, lm.mac$residuals, xlab="Predicted Price of BigMac", ylab="Residuals", main="Residual Plot")
qqnorm(lm.mac$residuals)
qqline(lm.mac$residuals)
```

The linearity assumption is not met because the scatterplot has a curved pattern and the residual plot fans out. Equal variance is not met because the residual plot fans out. Nearnly normal condition is not met because histogram of residuals is skewed to the right.

Errors independence is also not met because the residual plot thickens when we increase in predicted price of BigMac.  

### c
```{r}
library(MASS)
boxcox(lm.mac)
lm.adj <- lm((BigMac)^(-1/2)~EngSal, data=bigmac)
par(mfrow=c(2,2))
plot(bigmac$EngSal, (bigmac$BigMac)^(-1/2), xlab="Average Engineer's Salary", ylab="Price of BigMac Transformed")
abline(lm.adj, col="red")
hist(lm.adj$residuals, main="Histogram of Residuals", xlab="Transformed Residuals")
plot(lm.adj$fitted.values, lm.adj$residuals, xlab="Predicted Price of BigMac (Transformed)", ylab="Residuals", main="Residual Plot")
qqnorm(lm.adj$residuals)
qqline(lm.adj$residuals)
```

Using the Box Cox transformation, we decided to take the negative square root for Bigmac prices. After the transformation, the association looks roughtly linear and the residuals look closer to being normal (as seen from the histogram and the QQ plot).Also, the residual plot doesn't show any special pattern now: specifically, it doesn't get thicken as we increase in predicted Bigmac price. After the transformation, we think that the assumptions for linear regression are better met compared to the original model. 

In addition, we also tried -2/3 and -1 as the power of transformation, and both transformations will cause the residuals to deviate from normal. 

### d

```{r}
predict(lm.mac, newdata=data.frame(EngSal=70000))
```

The original model predicts that in a city in which the average Engineer's salary is $70,000, the price of a bigmac will be, on average, -$7.54. This is impossible.

### e

```{r}
predict(lm.adj, newdata=data.frame(EngSal=70000))
```

17.66^(-1/2)=0.238. 
We expect that a city with average engineer salary of $70,000 will have bigmacs that cost, on average, $17.66. 